# âš¡ Energy Consumption Forecasting

## ğŸ“‹ Project Overview

This project provides an end-to-end pipeline for forecasting energy consumption using time series data. It includes data loading, preprocessing, feature engineering, model training, evaluation, and deployment with a Streamlit web app for interactive forecasting and visualization.

## ğŸ‘¨â€ğŸ’» Author

**Hariharan S**  
- GitHub: [@HARIHARANS24](https://github.com/HARIHARANS24)
- LinkedIn: [Hariharan S](https://www.linkedin.com/in/hariharan-s-24/)
- Email: hariharans24@gmail.com

## âœ¨ Features

- **ğŸ”„ Data Processing Pipeline**
  - Raw data ingestion and validation
  - Automated data cleaning and preprocessing
  - Feature engineering with lag variables and time features
  - External data integration (weather, holidays)

- **ğŸ¤– Machine Learning Models**
  - XGBoost for traditional ML approach
  - LSTM for deep learning approach
  - Model comparison and selection
  - Hyperparameter tuning

- **ğŸ“Š Evaluation Metrics**
  - RMSE (Root Mean Square Error)
  - MAE (Mean Absolute Error)
  - MAPE (Mean Absolute Percentage Error)
  - Custom evaluation visualizations

- **ğŸŒ Interactive Web Application**
  - Streamlit-based dashboard
  - Real-time forecasting
  - Interactive visualizations
  - Historical data analysis

## ğŸ“ Project Structure

```plaintext
energy_consumption_forecasting/
â”‚
â”œâ”€â”€ ğŸ“‚ data/                           # Data directory
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                        # Raw source data (immutable)
â”‚   â”œâ”€â”€ ğŸ“‚ processed/                  # Cleaned and feature-engineered data
â”‚   â”œâ”€â”€ ğŸ“‚ external/                   # External data sources (weather, holidays)
â”‚   â””â”€â”€ ğŸ“„ README.md                   # Data description and sources info
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                      # Jupyter notebooks
â”‚   â”œâ”€â”€ ğŸ“„ exploratory_data_analysis.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ feature_engineering.ipynb
â”‚   â””â”€â”€ ğŸ“„ model_experiments.ipynb
â”‚
â”œâ”€â”€ ğŸ“‚ src/                           # Source code
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ data_loader.py         # Load raw & processed data
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ preprocess.py          # Cleaning & preprocessing functions
â”‚   â”‚   â””â”€â”€ ğŸ“„ feature_engineering.py # Feature creation & selection
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ models/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ base_model.py          # Abstract base class for models
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ lstm_model.py          # LSTM deep learning model
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ xgboost_model.py       # XGBoost model
â”‚   â”‚   â””â”€â”€ ğŸ“„ model_utils.py         # Training, evaluation, saving models
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ evaluation/
â”‚   â”‚   â””â”€â”€ ğŸ“„ metrics.py             # Custom metrics (RMSE, MAE, MAPE)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ utils/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ config.py              # Configuration loader (YAML/JSON)
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ logger.py              # Logging setup
â”‚   â”‚   â””â”€â”€ ğŸ“„ helpers.py             # Utility functions
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ visualization/
â”‚   â”‚   â””â”€â”€ ğŸ“„ viz.py                 # Visualization utilities
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“„ forecasting_pipeline.py    # Main pipeline orchestration
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                         # Unit tests
â”‚   â”œâ”€â”€ ğŸ“„ test_data_loader.py
â”‚   â”œâ”€â”€ ğŸ“„ test_preprocess.py
â”‚   â”œâ”€â”€ ğŸ“„ test_feature_engineering.py
â”‚   â”œâ”€â”€ ğŸ“„ test_models.py
â”‚   â””â”€â”€ ğŸ“„ test_forecasting_pipeline.py
â”‚
â”œâ”€â”€ ğŸ“‚ configs/                       # Configuration files
â”‚   â”œâ”€â”€ ğŸ“„ config.yaml                # All hyperparameters, paths, settings
â”‚   â””â”€â”€ ğŸ“„ logging.yaml               # Logging configuration
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                       # Utility scripts
â”‚   â”œâ”€â”€ ğŸ“„ run_train.sh              # Bash script to train model
â”‚   â”œâ”€â”€ ğŸ“„ run_inference.sh          # Bash script for inference
â”‚   â””â”€â”€ ğŸ“„ setup_env.sh              # Setup environment
â”‚
â”œâ”€â”€ ğŸ“‚ models/                        # Saved model artifacts
â”‚   â”œâ”€â”€ ğŸ“‚ lstm/                     # LSTM model checkpoints
â”‚   â””â”€â”€ ğŸ“‚ xgboost/                  # XGBoost model files
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸ“„ Dockerfile                    # Containerization for deployment
â”œâ”€â”€ ğŸ“„ docker-compose.yml           # Multi-container setup
â”œâ”€â”€ ğŸ“„ app.py                       # Streamlit web application
â”œâ”€â”€ ğŸ“„ main.py                      # Main entry point
â”œâ”€â”€ ğŸ“„ generate_synthetic_data_full.py # Data generation script
â”œâ”€â”€ ğŸ“„ LICENSE                      # MIT License
â””â”€â”€ ğŸ“„ .gitignore                   # Git ignore file
```

## ğŸš€ Setup Instructions

1. **ğŸ“¥ Clone the Repository**
   ```bash
   git clone https://github.com/HARIHARANS24/energy_consumption_forecasting.git
   cd energy_consumption_forecasting
   ```

2. **ğŸ”§ Set Up Python Environment**
   ```bash
   # Create virtual environment
   python3 -m venv venv
   
   # Activate virtual environment
   # On Windows:
   venv\Scripts\activate
   # On Unix/MacOS:
   source venv/bin/activate
   
   # Install dependencies
   pip install -r requirements.txt
   ```

3. **ğŸ“Š Generate Synthetic Data (Optional)**
   ```bash
   python generate_synthetic_data_full.py
   ```

4. **ğŸ§ª Run Tests**
   ```bash
   pytest tests/
   ```

5. **ğŸ¤– Train Models**
   ```bash
   # Using script
   bash scripts/run_train.sh
   
   # Or using Python directly
   python main.py --mode train
   ```

6. **ğŸŒ Launch Web Application**
   ```bash
   streamlit run app.py
   ```

## ğŸ’¡ Usage

### ğŸ“‚ Data Management
- Place raw time series CSV files in `data/raw/`
- Processed data will be stored in `data/processed/`
- External data (weather, holidays) should be placed in `data/external/`

### ğŸ¤– Model Training
- Configure model parameters in `configs/config.yaml`
- Run training scripts from `scripts/` directory
- Trained models are saved in `models/` directory

### ğŸŒ Web Application
- Access the Streamlit app at `http://localhost:8501`
- Upload new data or use existing datasets
- View forecasts and visualizations
- Download predictions and reports

## âš™ï¸ Configuration

### ğŸ”§ Model Parameters
Edit `configs/config.yaml` to modify:
- Model hyperparameters
- Feature engineering settings
- Training parameters
- Data paths
- Evaluation metrics

### ğŸ“ Logging
Configure logging in `configs/logging.yaml`:
- Log levels
- Output formats
- File paths

## ğŸ‘¨â€ğŸ’» Development

### âœ¨ Adding New Features
1. Create feature branch
2. Add tests in `tests/`
3. Implement feature
4. Run tests
5. Submit pull request

### ğŸ§ª Running Tests
```bash
# Run all tests
pytest tests/

# Run specific test file
pytest tests/test_models.py

# Run with coverage
pytest --cov=src tests/
```

## ğŸš¢ Deployment

### ğŸ³ Docker Deployment
1. Build Docker image:
   ```bash
   docker build -t energy-forecast .
   ```

2. Run container:
   ```bash
   docker run -p 8501:8501 energy-forecast
   ```

### ğŸ³ Docker Compose
For multi-container setup:
```bash
docker-compose up -d
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Thanks to all contributors
- Inspired by various time series forecasting projects
- Built with Streamlit, PyTorch, and XGBoost
